---
layout: about
title: about
permalink: /
subtitle: AI Safety Researcher | Mechanistic Interpretability Enthusiast | PhD Candidate at the <a href='https://www.uva.nl/en/profile/b/e/l.f.bereska/l.f.bereska.html'>University of Amsterdam</a>.

profile:
  align: right
  image: prof_pic.png
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>Chief Data Analytics Office</p>
    <p>Vanguard Headquarters</p>
    <p>Malvern, PA</p>

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I'm Travis, a Senior Data Scientist at Vanguard, excited to be taking the neural network knowledge from decades of neuroscience experiments to develop deep neural networks to help customer experience and reduce cost through automation.

### research focus

My work revolves around reverse engineering neural networks into human-interpretable algorithms. I'm particularly interested in:

- [Engineering monosemanticity](https://arxiv.org/abs/2211.09169) and implementing [sparse distillation](https://www.lesswrong.com/posts/MXabwqMwo3rkGqEW8/sparse-mlp-distillation) techniques in transformer models.
- Investigating the relationship between [mechanistic interpretability and adversarial robustness](https://leonardbereska.github.io/blog/2024/mechrobustproposal/).
- Analyzing [truth representations](http://arxiv.org/abs/2312.01037) and [simulacra](https://generative.ink/posts/simulators/) in large language models.
- Applying [singular learning theory](https://edmundlth.github.io/posts/overview-of-singular-learning-theory/) to examine phase transitions in algorithmic tasks.
- Mechanistically interpreting [prior-fitted tabular transformers](https://arxiv.org/abs/2207.01848).
- Creating sparse boolean circuits (inspired by [computation in superposition](https://arxiv.org/abs/2408.05451)) as testbeds and benchmarks for interpretability methods.
 
If you find any of these topics interesting, please reach out.

As part of the [AI Safety Initiative Amsterdam](https://aisafetyamsterdam.com/), I'm actively involved in promoting AI safety research and awareness. We organize events, facilitate reading groups, and foster discussions on crucial AI safety topics.

I'm also passionate about nurturing the next generation of AI safety researchers. I've been involved in teaching courses and supervising numerous Master's students on projects ranging from detecting bias, eliciting truth in LLMs, to interpretability in medical AI applications.

### beyond research

When I'm not diving into the intricacies of neural networks, you might find me:

- Practicing yoga or meditation to maintain balance.
- Reading science-fiction novels (recently discovered Vernor Vinge's work for a plausible treatment of AI singularity).
- Playing with my two chihuahuas, Cicchetti and Pancetta. 
- Exploring Amsterdam's culinary scene (always on the lookout for the best vegan spots!)
- Brushing up on my Mandarin or picking up Dutch phrases.
- Engaging in discussions about the future of AI and its implications for society.